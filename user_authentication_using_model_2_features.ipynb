{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One class SVM model using automatically extracted features - Model 1\n",
    "\n",
    "This notebook contains the code to run experiments for intruder detection using the first CNN model (Model 1) in order to automatically\n",
    "extract features from gestures. The model should extract both single-gesture features, as well as inter-gesture features relating to the\n",
    "time difference in a sliding window. \n",
    "\n",
    "The experiments are run similar to the ones for the 1-class SVM with manually engineered features. However, these notebook requries a `models` folder\n",
    "containig the trained models, and users used for training the models (in order to be excluded). Links to these resources can be found in the `README.md` file. \n",
    "\n",
    "Experiments run multithreaded and save the output in the `OUTPUT_DIR` folder. Set the `N_THREADS` variable to the number of threads you want to use (recommended 4-8 threads on a normal machine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.draw import line_aa\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.svm import OneClassSVM\n",
    "import itertools\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "from config import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for the experiments\n",
    "Set the parameters with which the experiment will be run. Below is a description for each of them.\n",
    "* `DATASET`: Specify which dataset to be used. Choose between BRAINRUN and TOUCHALYTICS. The paths for the dataset are assumed to be at `./datasets`, and can be changed in the `config.py` file.\n",
    "* `N_THREADS`: Number of threads to use for the experiment.\n",
    "* `OUTPUT_DIR`: Directory to which the results will be written.\n",
    "* `MODELS_DIR`: Directory containing the trained models.\n",
    "\n",
    "Here we also set the parameters for data cleanup and parsing, although these are best left constant.\n",
    "* `MIN_SESSION_GESTURES`: Minimum number of gestures in a session to be considered. Left at 140 as it has shown to produce good results, and include a large number of users\n",
    "* `SCREENS`: The screens to use from the BrainRun dataset when performing the experiment (ignored for the Touchalytics dataset). The experiments were originally performed using either one or both of the screens *MathisisGame* or *FocusGame*, as they contain predominantly swipe data.\n",
    "* `WINDOW_SIZE`: Needs to be the same as the size of the input to the model (constant 11 throught the experiment). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = TOUCHALYTICS # Choose between BRAINRUN and TOUCHALYTICS\n",
    "N_THREADS = 32\n",
    "OUTPUT_DIR = 'test_results3/'\n",
    "MODELS_DIR = 'models/model_2_ws_1' # Choose between window size 1 and 11\n",
    "\n",
    "MIN_SESSION_GESTURES = 140\n",
    "SCREENS = ['MathisisGame', 'FocusGame']\n",
    "\n",
    "# WARNING: Window size has to be the same on the model has been trained on, otherwise the results\n",
    "# may not be accurate.\n",
    "WINDOW_SIZE = 11 if '11' in MODELS_DIR else 1\n",
    "# Size of the input image (assume square). All experiments used an image of size 32x32.\n",
    "IMAGE_SIZE = 32\n",
    "# Size of the canvas to draw the gesture. All experiments used a canvas of size 128x128, and \n",
    "# the resulting images were downsampled to 32x32.\n",
    "CANVAS_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility methods for extracting features and splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gesture_to_points(data):\n",
    "    '''\n",
    "    Convert a gesture to a list of the first 5 and last 5 points (flatenned)\n",
    "    '''\n",
    "    result = []\n",
    "    points = [(data[0]['x0'], data[0]['y0'])] + [(x['moveX'], x['moveY']) for x in data]\n",
    "    points = np.array(points)\n",
    "\n",
    "    res = np.nan_to_num(result)\n",
    "    first_three_points = points[:5].flatten() \n",
    "    last_three_points = points[-5:].flatten() \n",
    "    first_three_points.resize((10,))\n",
    "    last_three_points.resize((10,))\n",
    "\n",
    "    return np.concatenate([res, first_three_points, last_three_points])\n",
    "    \n",
    "\n",
    "def draw_line(x0, y0, x1, y1, img_size, img, vel = 1):\n",
    "    '''\n",
    "    Draws a line starting from (x0, y0) and ending at (x1, y1) on the image `img`, with the intensity\n",
    "    set by `vel`.\n",
    "    '''\n",
    "    rr,cc,val = line_aa(int(x0 * img_size), int(y0 * img_size), int(x1 * img_size), int(y1 * img_size))\n",
    "    if x0 > 1 or y0 > 1 or x1 > 1 or y1 > 1:\n",
    "        print(x0, y0, x1, y1)\n",
    "    img[rr,cc] = val * vel\n",
    "\n",
    "def points_to_image(points):\n",
    "    '''\n",
    "    Converts a list of points ((x,y) pairs) into an image of size `IMAGE_SIZE` x `IMAGE_SIZE`.\n",
    "    Encodes velocities between each pair of points as intensity in the image.\n",
    "    '''\n",
    "    init = np.zeros((CANVAS_SIZE, CANVAS_SIZE))\n",
    "\n",
    "    # Get a list of velocities between pairwise points\n",
    "    velocities = [np.linalg.norm(p1 - p2) for p1, p2 in zip(points[:-1], points[1:])]\n",
    "    velocities = (velocities - np.min(velocities)) / (np.ptp(velocities) or 1)\n",
    "\n",
    "    # Draw each line segment\n",
    "    x0, y0 = points[0][1], points[0][0]\n",
    "    for datapoint, velocity in zip(points[1:], velocities):\n",
    "        draw_line(x0, y0, datapoint[1], datapoint[0], 128 - 1, init, vel = velocity)\n",
    "        x0, y0 = datapoint[1], datapoint[0]\n",
    "\n",
    "    # Resize the image to the desired size\n",
    "    res = init\n",
    "    res = cv2.resize(init, dsize=(IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "    mean, std = res.mean(), res.std()\n",
    "    res = (res - mean) / (std or 1)\n",
    "    res = res.reshape(IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "    return res\n",
    "\n",
    "\n",
    "def gesture_to_image(c):\n",
    "    '''\n",
    "    Convert a gesture into an image representing the path of the gesture.\n",
    "    '''\n",
    "    clip = lambda x: np.clip(x, 0, 1)\n",
    "    img_data = c['data']\n",
    "    \n",
    "    points = np.array([[clip(img_data[0]['x0']), clip(img_data[0]['y0'])]] + [[clip(pt['moveX']), clip(pt['moveY'])] for pt in img_data])\n",
    "    return points_to_image(points) \n",
    "\n",
    "def window_to_datapoint(window):\n",
    "    '''\n",
    "    Sum WINDOW_SIZE windows into a single image.\n",
    "    '''\n",
    "    return np.sum(window, axis = 0)\n",
    "\n",
    "def session_to_datapoints(s):\n",
    "    '''\n",
    "    Convert a session to a series of datapoints, representing the 128 feature embeddings of\n",
    "    the windows.\n",
    "    '''\n",
    "    featurized_session = np.array([gesture_to_image(x) for x in s['gestures']])\n",
    "    sliding_windows = (\n",
    "        np.expand_dims(np.arange(WINDOW_SIZE), 0) +\n",
    "        np.expand_dims(np.arange(len(featurized_session) - WINDOW_SIZE), 0).T\n",
    "    )\n",
    "\n",
    "    temp = np.array([window_to_datapoint(window) for window in featurized_session[sliding_windows]])\n",
    "    return deep_model.predict(temp)\n",
    "\n",
    "\n",
    "def get_train_indices(size, test_size = 0.2, gap = WINDOW_SIZE, max_size = np.inf):\n",
    "    '''\n",
    "    Returns the train indices for a given session.\n",
    "    Leaves a space of `gap` between the train and test indices\n",
    "    '''\n",
    "    size = min(size, max_size)\n",
    "    middle = int(size * (1 - test_size))\n",
    "    middle = min(middle, max_size)\n",
    "    return np.arange(middle - gap)\n",
    "\n",
    "def get_test_indices(size, test_size = 0.2, gap = WINDOW_SIZE, max_size = np.inf):\n",
    "    '''\n",
    "    Returns the test indices for a given session.\n",
    "    '''\n",
    "    size = min(size, max_size)\n",
    "    middle = int(size * (1 - test_size))\n",
    "    return np.arange(middle, size)\n",
    "\n",
    "def get_intruder_size(size, test_size = 0.2, gap = WINDOW_SIZE, max_size = np.inf):\n",
    "    '''\n",
    "    Returns validation and test indices for intruders. Also leaves a space of `gap` \n",
    "    between the validation and test indices.\n",
    "    '''\n",
    "    size = min(size, max_size)\n",
    "    middle = int(size * (1 - test_size))\n",
    "    validation_middle = int(size * (1 - test_size / 2))\n",
    "    return np.arange(middle, validation_middle - gap), np.arange(validation_middle, size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for filtering and parsing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "def prefilter_session(s):\n",
    "    '''\n",
    "    Filters the session, orders gestures chronologically and removes gestures that are outliers or from different screens\n",
    "    '''\n",
    "    s['gestures'].sort(key = lambda x: x['t_start'])\n",
    "    s['gestures'] = [x for x in s['gestures'] \n",
    "        if x['t_stop'] - x['t_start'] > 70 and x['t_stop'] - x['t_start'] < (1000 if DATASET == BRAINRUN else 2000) and \n",
    "        ((x['screen'].split(' ')[0] in SCREENS and x['type'] == 'swipe') if DATASET == BRAINRUN else True)]\n",
    "\n",
    "def parse_user(user_id):\n",
    "    '''\n",
    "    Parses all the sessions for a user with the given id. Deletes sessions that are too short after filtering them.\n",
    "    '''\n",
    "\n",
    "    i = 0\n",
    "    should_delete = False\n",
    "    while i < len(users[user_id]['devices'][0]['sessions']):\n",
    "        prefilter_session(users[user_id]['devices'][0]['sessions'][i])\n",
    "\n",
    "        if len(users[user_id]['devices'][0]['sessions'][i]['gestures']) < MIN_SESSION_GESTURES or should_delete:\n",
    "            del users[user_id]['devices'][0]['sessions'][i]\n",
    "        else:\n",
    "            users[user_id]['devices'][0]['sessions'][i] = session_to_datapoints(users[user_id]['devices'][0]['sessions'][i])\n",
    "            # Outlier detection\n",
    "            clf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "            users[user_id]['devices'][0]['sessions'][i] = \\\n",
    "                users[user_id]['devices'][0]['sessions'][i][np.where(clf.fit_predict(users[user_id]['devices'][0]['sessions'][i]) == 1)]\n",
    "            i += 1\n",
    "\n",
    "def get_users_over_gestures(number_of_gestures = 140):\n",
    "    '''\n",
    "    Returns an array with the indices of all users with more than number_of_gestures gestures.\n",
    "    '''\n",
    "    uc = np.zeros((len(users), ))\n",
    "    for i in range(len(users)):\n",
    "        uc[i] = 0\n",
    "        for session in users[i]['devices'][0]['sessions']:\n",
    "            uc[i] += session.shape[0]\n",
    "\n",
    "    return np.where(uc > number_of_gestures)[0]\n",
    "\n",
    "def compute_eer(label, pred):\n",
    "    \"\"\"\n",
    "    Computes EER given a list of labels and predictions.\n",
    "\n",
    "    Code inspired by https://github.com/YuanGongND/python-compute-eer\n",
    "    \"\"\"\n",
    "    # all fpr, tpr, fnr, fnr, threshold are lists (in the format of np.array)\n",
    "    fpr, tpr, threshold = roc_curve(label, pred)\n",
    "    fnr = 1 - tpr\n",
    "\n",
    "    # theoretically eer from fpr and eer from fnr should be identical but they can be slightly differ in reality\n",
    "    eer_1 = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "    eer_2 = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "\n",
    "    # return the mean of eer from fpr and from fnr\n",
    "    eer = (eer_1 + eer_2) / 2\n",
    "    return eer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for multithreaded experiments\n",
    "\n",
    "Since the datasets are large and a iteration is done for each users, the experiments take a significant amount of time to run on a normal machine. Multiprocessing was used to run the experiments in parallel on a powerful machine, using 32 cores (this reduces the time to about an hour). Below is the code used to run the experiments using different processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter space (for hyperparameter tuning)\n",
    "parameters = [{\n",
    "    'kernel': ['rbf'], 'gamma': [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001], 'nu': [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],},\n",
    "    ]\n",
    "\n",
    "def run_experiment_multithreaded(output_path, dataset, valid_users):\n",
    "    '''\n",
    "    Runs experiment with the data provided in the `users` variable, and outputs the results to `output_path`.\n",
    "    The first and second userss of the BrainRun dataset contain significantly more data than the others, so filter \n",
    "    the hyperparameter selection is run multithreaded for them.\n",
    "    '''\n",
    "    FILE_PATH = f'{output_path}/{dataset}'\n",
    "\n",
    "    def run_experiment_for_user(user_id, users, valid_users, parameters):        \n",
    "        X_train = np.concatenate([session[get_train_indices(session.shape[0],)] for session in users[int(user_id)]['devices'][0]['sessions']])\n",
    "        X_test = np.concatenate([session[get_test_indices(session.shape[0]),] for session in users[int(user_id)]['devices'][0]['sessions']])\n",
    "        \n",
    "        # Cross validation - choose best hyperparameters for each user\n",
    "        # Default hyperparameters (will be replaced by the best hyperparameters)\n",
    "        hyperparameters = [(100, {'kernel':'rbf', 'gamma':0.8, 'nu': 0.3})]\n",
    "        for hyper_pair in ParameterGrid(parameters):\n",
    "            # Use time series split cross-validation\n",
    "            cv = TimeSeriesSplit(n_splits=4, gap = WINDOW_SIZE)\n",
    "            avg_eer = []\n",
    "            for train, test in cv.split(X_train):\n",
    "                clf = OneClassSVM(\n",
    "                    kernel = hyper_pair['kernel'], \n",
    "                    nu=hyper_pair['nu'], \n",
    "                    degree = hyper_pair['degree'] if 'degree' in hyper_pair else 0, \n",
    "                    gamma = hyper_pair['gamma'] if 'gamma' in hyper_pair else 0,)\n",
    "\n",
    "                scaler = StandardScaler()\n",
    "                clf.fit(scaler.fit_transform(X_train[train]))\n",
    "\n",
    "                # Predict\n",
    "                res = np.concatenate([\n",
    "                    clf.decision_function(scaler.transform(X_train[test])), *[\n",
    "                        clf.decision_function(scaler.transform(session[get_intruder_size(session.shape[0])[0]])) for other_uid in valid_users[valid_users != user_id] for session in users[other_uid]['devices'][0]['sessions']]\n",
    "                ])\n",
    "                # Build labels based on test data and result\n",
    "                y_test = np.concatenate([np.zeros((test.shape[0],)) + 1, np.zeros((res.shape[0] - test.shape[0],)) - 1])\n",
    "                \n",
    "                # Set inf and -inf predictions to a reasonable number\n",
    "                res[np.isneginf(res)] = -100000\n",
    "                res[np.isposinf(res)] = 100000\n",
    "                avg_eer.append(compute_eer(y_test, res))\n",
    "            hyperparameters.append((np.mean(avg_eer), hyper_pair))\n",
    "        \n",
    "        # Get the best hyperparams\n",
    "        best_hyperparameters = sorted(hyperparameters, key=lambda x: x[0])[0][1]\n",
    "        svm = OneClassSVM(\n",
    "                    kernel = best_hyperparameters['kernel'], \n",
    "                    nu=best_hyperparameters['nu'], \n",
    "                    degree = best_hyperparameters['degree'] if 'degree' in best_hyperparameters else 0, \n",
    "                    gamma = best_hyperparameters['gamma'] if 'gamma' in best_hyperparameters else 0,)\n",
    "\n",
    "        # Normalize the data using StandardScaler - fit only on train data and use the same scaler for both train and test\n",
    "        scaler = StandardScaler()\n",
    "        svm.fit(scaler.fit_transform(X_train))\n",
    "\n",
    "        # Predict\n",
    "        res = np.concatenate([\n",
    "            svm.decision_function(scaler.transform(X_test)), *[\n",
    "                svm.decision_function(scaler.transform(session[get_intruder_size(session.shape[0])[1]])) for other_uid in valid_users[valid_users != user_id] for session in users[other_uid]['devices'][0]['sessions']]\n",
    "        ])\n",
    "\n",
    "        # Build labels based on the test data and result - user labels are set as 1, intruder labels are set as -1\n",
    "        y_test = np.concatenate([np.zeros((X_test.shape[0],)) + 1, np.zeros((res.shape[0] - X_test.shape[0],)) - 1])\n",
    "\n",
    "        # Save results with pickle to a file\n",
    "        with open(f'{FILE_PATH}/user_{user_id}.pkl', 'wb') as f:\n",
    "            pickle.dump((y_test, res, hyperparameters), f)\n",
    "\n",
    "    def find_hyper(user_id, hyper_pair, users, valid_users, X_train, hyperparameters):\n",
    "        '''\n",
    "        Finds the best hyperparmaters for a specific user.\n",
    "        '''\n",
    "        cv = TimeSeriesSplit(n_splits=4, gap = WINDOW_SIZE)\n",
    "        avg_eer = []\n",
    "        for train, test in cv.split(X_train):\n",
    "            clf = OneClassSVM(\n",
    "                kernel = hyper_pair['kernel'], \n",
    "                nu=hyper_pair['nu'], \n",
    "                degree = hyper_pair['degree'] if 'degree' in hyper_pair else 0, \n",
    "                gamma = hyper_pair['gamma'] if 'gamma' in hyper_pair else 0,)\n",
    "            scaler = StandardScaler()\n",
    "            clf.fit(scaler.fit_transform(X_train[train]))\n",
    "            res = np.concatenate([\n",
    "                clf.decision_function(scaler.transform(X_train[test])), *[\n",
    "                    clf.decision_function(scaler.transform(session[get_intruder_size(session.shape[0])[0]])) for other_uid in valid_users[valid_users != user_id] for session in users[other_uid]['devices'][0]['sessions']]\n",
    "            ])\n",
    "            y_test = np.concatenate([np.zeros((test.shape[0],)) + 1, np.zeros((res.shape[0] - test.shape[0],)) - 1])\n",
    "            \n",
    "            res[np.isneginf(res)] = -1000\n",
    "            res[np.isposinf(res)] = 1000\n",
    "            avg_eer.append(compute_eer(y_test, res))\n",
    "        hyperparameters.append((np.mean(avg_eer), hyper_pair))\n",
    "\n",
    "    if not os.path.exists(FILE_PATH):\n",
    "        os.makedirs(FILE_PATH)\n",
    "\n",
    "    for user_id in list(set(valid_users).intersection([0,1] if DATASET == BRAINRUN else [])):\n",
    "        max_train_per_session = np.inf\n",
    "\n",
    "        # Uncomment this line to test the effect of different number of gestures\n",
    "        # max_train_per_session = int(140 / len(users[int(user_id)]['devices'][0]['sessions']))\n",
    "        \n",
    "        X_train = np.concatenate([session[get_train_indices(session.shape[0], max_size=max_train_per_session)] for session in users[int(user_id)]['devices'][0]['sessions']])\n",
    "        X_test = np.concatenate([session[get_test_indices(session.shape[0]),] for session in users[int(user_id)]['devices'][0]['sessions']])\n",
    "\n",
    "        # Cross validation\n",
    "        # Users 0 and 1 of the BrainRun dataset contain significantly more data, and cross-validation is done multi-threaded for efficiency.\n",
    "        # For all other users cross-validation is done in a single thread, as the overhead is not justified.\n",
    "        threads = []\n",
    "        cid = 0\n",
    "        can_exit = False\n",
    "\n",
    "        hyper_grid = list(ParameterGrid(parameters))\n",
    "        manager = mp.Manager()\n",
    "        hyperparameters = manager.list()\n",
    "\n",
    "        pbar = tqdm(total=len(hyper_grid))\n",
    "        while not can_exit:\n",
    "            while len(threads) < N_THREADS and cid < len(hyper_grid):\n",
    "                thread = mp.Process(target=find_hyper, args=(user_id, hyper_grid[cid], users, valid_users, X_train, hyperparameters))\n",
    "                thread.start()\n",
    "                threads.append(thread)\n",
    "                pbar.update(1)\n",
    "                cid += 1\n",
    "\n",
    "            for thread in threads:\n",
    "                if not thread.is_alive():\n",
    "                    thread.join()\n",
    "                    threads.remove(thread)\n",
    "\n",
    "            if(len(threads) == 0):\n",
    "                can_exit = True\n",
    "            time.sleep(1)\n",
    "        pbar.close()\n",
    "\n",
    "        # End hyperparameter search\n",
    "\n",
    "        # Fit and test the model (same process as before)\n",
    "        hyperparameters = list(hyperparameters)\n",
    "        best_hyperparameters = sorted(hyperparameters, key=lambda x: x[0])[0][1]\n",
    "        svm = OneClassSVM(\n",
    "                    kernel = best_hyperparameters['kernel'], \n",
    "                    nu=best_hyperparameters['nu'], \n",
    "                    degree = best_hyperparameters['degree'] if 'degree' in best_hyperparameters else 0, \n",
    "                    gamma = best_hyperparameters['gamma'] if 'gamma' in best_hyperparameters else 0,)\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        svm.fit(scaler.fit_transform(X_train))\n",
    "\n",
    "        res = np.concatenate([\n",
    "            svm.decision_function(scaler.transform(X_test)), *[\n",
    "                svm.decision_function(scaler.transform(session[get_intruder_size(session.shape[0])[1]])) for other_uid in valid_users[valid_users != user_id] for session in users[other_uid]['devices'][0]['sessions']]\n",
    "        ])\n",
    "\n",
    "        y_test = np.concatenate([np.zeros((X_test.shape[0],)) + 1, np.zeros((res.shape[0] - X_test.shape[0],)) - 1])\n",
    "\n",
    "        # Save results with pickle to a file\n",
    "        with open(f'{FILE_PATH}/user_{user_id}.pkl', 'wb') as f:\n",
    "            pickle.dump((y_test, res, hyperparameters), f)\n",
    "\n",
    "    threads = []\n",
    "    cid = 0\n",
    "    can_exit = False\n",
    "\n",
    "    if not os.path.exists(FILE_PATH):\n",
    "        os.makedirs(FILE_PATH)\n",
    "\n",
    "    # Same process of excluding the first two users for the BrainRun dataset\n",
    "    vu = list(set(valid_users).difference([0,1] if DATASET == BRAINRUN else []))\n",
    "    pbar = tqdm(total=len(vu))\n",
    "    while not can_exit:\n",
    "        while len(threads) < N_THREADS and cid < len(vu):\n",
    "            user_id = vu[cid]\n",
    "            thread = mp.Process(target=run_experiment_for_user, args=(vu[cid], users, valid_users, parameters))\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "            cid += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "        for thread in threads:\n",
    "            if not thread.is_alive():\n",
    "                thread.join()\n",
    "                threads.remove(thread)\n",
    "\n",
    "        if(len(threads) == 0):\n",
    "            can_exit = True\n",
    "\n",
    "        time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:43<00:00,  1.07s/it]\n",
      "100%|██████████| 41/41 [00:55<00:00,  1.35s/it]\n",
      "  2%|▏         | 1/41 [00:02<01:25,  2.13s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c8185e376af7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Parse data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mparse_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mvalid_users\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_users_over_gestures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m140\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-230b85528f95>\u001b[0m in \u001b[0;36mparse_user\u001b[0;34m(user_id)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'devices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sessions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0musers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'devices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sessions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession_to_datapoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'devices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sessions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;31m# Outlier detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalOutlierFactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontamination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-780818e3bb77>\u001b[0m in \u001b[0;36msession_to_datapoints\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mthe\u001b[0m \u001b[0mwindows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     '''\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mfeaturized_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgesture_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gestures'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     sliding_windows = (\n\u001b[1;32m     77\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWINDOW_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-780818e3bb77>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mthe\u001b[0m \u001b[0mwindows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     '''\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mfeaturized_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgesture_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gestures'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     sliding_windows = (\n\u001b[1;32m     77\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWINDOW_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-780818e3bb77>\u001b[0m in \u001b[0;36mgesture_to_image\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mimg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'moveX'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'moveY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpoints_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-780818e3bb77>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mimg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'moveX'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'moveY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpoints_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-780818e3bb77>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mConvert\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgesture\u001b[0m \u001b[0minto\u001b[0m \u001b[0man\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mrepresenting\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgesture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     '''\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mimg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mclip\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/local/home/r96133vi/venv/lib64/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mclip\u001b[0;34m(a, a_min, a_max, out, **kwargs)\u001b[0m\n\u001b[1;32m   2095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m     \"\"\"\n\u001b[0;32m-> 2097\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/home/r96133vi/venv/lib64/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/home/r96133vi/venv/lib64/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_clip\u001b[0;34m(a, min, max, out, casting, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# This deprecation probably incurs a substantial slowdown for small arrays,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# it will be good to get rid of it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_clip_dep_is_byte_swapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_clip_dep_is_byte_swapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0musing_deprecated_nan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_clip_dep_is_scalar_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/home/r96133vi/venv/lib64/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_clip_dep_is_byte_swapped\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_clip_dep_is_byte_swapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Do 10 iterations, using the users the model was not trained on each time\n",
    "for iteration in range(10):\n",
    "    with open(f'{MODELS_DIR}/results/iteration_{iteration}.pkl', 'rb') as f:\n",
    "        u_training, u_testing, *_ = pickle.load(f)\n",
    "\n",
    "    # Only u_testing will be used \n",
    "    USERS_USED_FOR_TRAINING_FEAT_EXTRACTOR = u_training\n",
    "    USERS_USED_FOR_TESTING_GENERALIZATION = u_testing\n",
    "\n",
    "    # Load the model and remove the last layers, until the embedding layer is reached\n",
    "    deep_model = models.load_model(f'{MODELS_DIR}/models/simple_cnn_128_embedding_{iteration}.h5')\n",
    "    deep_model = models.Model(inputs = deep_model.input, outputs = deep_model.layers[-3].output)\n",
    "\n",
    "    # Load data\n",
    "    if DATASET == BRAINRUN:\n",
    "        with open('brainrun_full_not_parsed.pkl', 'rb') as f:\n",
    "            users = pickle.load(f)\n",
    "            valid_users = []\n",
    "            # Keep only the users on which the model wasn't trained on\n",
    "            for i, user in enumerate(users):\n",
    "                if i in USERS_USED_FOR_TESTING_GENERALIZATION:\n",
    "                    valid_users.append(user)\n",
    "\n",
    "            users = valid_users\n",
    "    if DATASET == TOUCHALYTICS:\n",
    "        with open('touchalytics_full_not_parsed.pkl', 'rb') as f:\n",
    "            users = pickle.load(f)\n",
    "\n",
    "    # Parse data\n",
    "    for user in tqdm(range(len(users))):\n",
    "        parse_user(user)\n",
    "\n",
    "    valid_users = get_users_over_gestures(140)\n",
    "\n",
    "    run_experiment_multithreaded(OUTPUT_DIR, iteration, valid_users)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecc757a38b814f9d9a78e27a3f0556e4d5be26951c473c897a83b93183395c00"
  },
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
