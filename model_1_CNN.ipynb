{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CNN model 1\n",
        "\n",
        "In this CNN model, the data representation is similar to the one used in [this paper](https://ieeexplore.ieee.org/document/7458136), and in the HAR field using motion sensors. \n",
        "The first and last 5 points of a gesture are flattened and concatenated in a feature vector, to which time information is added. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A0v6Qaw9htTS"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tqdm import tqdm\n",
        "\n",
        "import keras_tuner as kt\n",
        "from config import *\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters for the experiments\n",
        "Set the parameters with which the experiment will be run. Below is a description for each of them.\n",
        "* `DATASET`: Specify which dataset to be used. Only `BRAINRUN` is available for theses experiments The paths for the dataset are assumed to be at `./datasets`, and can be changed in the `config.py` file.\n",
        "* `MODELS_DIR`: Directory where to save trained models to be used in user identification.\n",
        "\n",
        "Here parameters for data cleanup and parsing are also set, although these are best left constant.\n",
        "* `MIN_SESSION_GESTURES`: Minimum number of gestures in a session to be considered. Left at 140 as it has shown to produce good results, and include a large number of users\n",
        "* `SCREENS`: The screens to use from the BrainRun dataset when performing the experiment (ignored for the Touchalytics dataset). The experiments were originally performed using either one or both of the screens *MathisisGame* or *FocusGame*, as they contain predominantly swipe data.\n",
        "* `WINDOW_SIZE`: Needs to be the size of the CNN input layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RvbgC097htTZ"
      },
      "outputs": [],
      "source": [
        "# Training only performed on the BrainRun dataset\n",
        "DATASET = BRAINRUN\n",
        "MODELS_DIR = 'model_1'\n",
        "\n",
        "MIN_SESSION_GESTURES = 140\n",
        "SCREENS = ['MathisisGame', 'FocusGame']\n",
        "\n",
        "# WARNING: Window size has to be set to the size of the model input layer (default 11)\n",
        "WINDOW_SIZE = 11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utility methods for parsing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cD2UXrzBhtTe"
      },
      "outputs": [],
      "source": [
        "def extract_features(data):\n",
        "    '''\n",
        "    Convert gesture to a vector of length 20, representing the coordinates of the first 5 and last 5 points.    \n",
        "    '''\n",
        "    result = []\n",
        "    points = [(data[0]['x0'], data[0]['y0'])] + [(x['moveX'], x['moveY']) for x in data]\n",
        "    points = np.array(points)\n",
        "\n",
        "    res = np.nan_to_num(result)\n",
        "    first_five_points = points[:5].flatten() \n",
        "    last_five_points = points[-5:].flatten() \n",
        "    first_five_points.resize((10,))\n",
        "    last_five_points.resize((10,))\n",
        "\n",
        "    return np.concatenate([res, first_five_points, last_five_points])\n",
        "    \n",
        "def gesture_to_data(c):\n",
        "    '''\n",
        "    Convert a gesture to a vector of length 23, containing start and stop time, gesture duration and coordinates of the \n",
        "    first and last 5 points.\n",
        "    '''\n",
        "    delta_time = (c['t_stop'] - c['t_start']) / 1000\n",
        "    extra_features = extract_features(c['data'])\n",
        "    return np.concatenate([[c['t_start'], c['t_stop'], delta_time], extra_features])\n",
        "\n",
        "def window_to_datapoint(window):\n",
        "    '''\n",
        "    Convert a window of gesture to a datapoint to be used in training the model.\n",
        "    Drop the start and stop time, as the user may be identified uniquely by it.\n",
        "    Add time from start of window and time between gesture as extra features.\n",
        "    '''\n",
        "    return np.concatenate([window[:, 2:], # Exclude start and stop time\n",
        "        np.concatenate([[0], (window[1:, 0] - window[0, 1]).flatten() / 1000]).reshape(window.shape[0],1), # Window start - initial point stop\n",
        "        np.concatenate([[0], (window[1:, 0] - window[:-1, 1]).flatten() / 1000]).reshape(window.shape[0],1)], axis = 1).reshape(window.shape[0], window.shape[1], 1) # Window start - previous window stop\n",
        "\n",
        "def session_to_datapoints(s):\n",
        "    '''\n",
        "    Convert a session to a series of datapoints, each representing a window of length WINDOW_SIZE.\n",
        "    '''\n",
        "    featurized_session = np.array([gesture_to_data(x) for x in s['gestures']])\n",
        "    sliding_windows = (\n",
        "        np.expand_dims(np.arange(WINDOW_SIZE), 0) +\n",
        "        np.expand_dims(np.arange(len(featurized_session) - WINDOW_SIZE), 0).T\n",
        "    )\n",
        "\n",
        "    return np.array([window_to_datapoint(window) for window in featurized_session[sliding_windows]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Methods for filtering and parsing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b0jYM0CLhtTi"
      },
      "outputs": [],
      "source": [
        "# Limit the size of the first and second user to the maximum number of  gestures in\n",
        "# remaining dataset to avoid imbalance\n",
        "LIMIT_GESTURES_PER_USER = 6825\n",
        "\n",
        "def prefilter_session(s):\n",
        "    '''\n",
        "    Filters the session, orders gestures chronologically and removes gestures that are outliers or from different screens\n",
        "    '''\n",
        "    s['gestures'].sort(key = lambda x: x['t_start'])\n",
        "    s['gestures'] = [x for x in s['gestures'] \n",
        "        if x['t_stop'] - x['t_start'] > 70 and x['t_stop'] - x['t_start'] < (1000 if DATASET == BRAINRUN else 2000) and \n",
        "        ((x['screen'].split(' ')[0] in SCREENS and x['type'] == 'swipe') if DATASET == BRAINRUN else True)]\n",
        "\n",
        "def parse_user(user_id):\n",
        "    '''\n",
        "    Parses all the sessions for a user with the given id. Deletes sessions that are too short after filtering them.\n",
        "    '''\n",
        "    i = 0\n",
        "\n",
        "    while i < len(users[user_id]['devices'][0]['sessions']):\n",
        "        prefilter_session(users[user_id]['devices'][0]['sessions'][i])\n",
        "\n",
        "        if len(users[user_id]['devices'][0]['sessions'][i]['gestures']) < MIN_SESSION_GESTURES:\n",
        "            del users[user_id]['devices'][0]['sessions'][i]\n",
        "        else:\n",
        "            users[user_id]['devices'][0]['sessions'][i] = session_to_datapoints(users[user_id]['devices'][0]['sessions'][i])\n",
        "            i += 1\n",
        "\n",
        "    # Limit gestures for the first and second user\n",
        "    # Select gestures stratified in order to include as evenly as possible from all sessions\n",
        "    inx_len = np.argsort([len(x) for x in users[user_id]['devices'][0]['sessions']])\n",
        "    sessions_remaining = len(users[user_id]['devices'][0]['sessions'])\n",
        "    gestures_remaining = LIMIT_GESTURES_PER_USER\n",
        "    for i in inx_len:\n",
        "        gestures_this_session = int(gestures_remaining / sessions_remaining)\n",
        "        gestures_remaining -= gestures_this_session\n",
        "        users[user_id]['devices'][0]['sessions'][i] = users[user_id]['devices'][0]['sessions'][i][:gestures_this_session]\n",
        "        sessions_remaining -= 1\n",
        "\n",
        "def get_users_over_gestures(number_of_gestures = 140):\n",
        "    '''\n",
        "    Returns an array with the indices of all users with more than number_of_gestures gestures.\n",
        "    '''\n",
        "    uc = np.zeros((len(users), ))\n",
        "    for i in range(len(users)):\n",
        "        uc[i] = 0\n",
        "        for session in users[i]['devices'][0]['sessions']:\n",
        "            uc[i] += session.shape[0]\n",
        "\n",
        "    return np.where(uc > number_of_gestures)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Methods used for splitting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Bp2bu9-EhtTm"
      },
      "outputs": [],
      "source": [
        "def get_train_indices(size, test_size = 0.2, val_size = 0.1, gap = WINDOW_SIZE, max_size = 50000):\n",
        "    size = min(size, max_size)\n",
        "    middle = int(size * (1 - test_size - val_size))\n",
        "    return np.arange(middle - gap - 5)\n",
        "\n",
        "def get_val_indices(size, test_size = 0.2, val_size = 0.1, gap = WINDOW_SIZE, max_size = 50000):\n",
        "    size = min(size, max_size)\n",
        "    start = int(size * (1 - test_size - val_size))\n",
        "    end = int(size * (1 - test_size))\n",
        "    return np.arange(start - 5, end - gap)\n",
        "\n",
        "def get_test_indices(size, test_size = 0.2, gap = WINDOW_SIZE, max_size = 50000):\n",
        "    size = min(size, max_size)\n",
        "    middle = int(size * (1 - test_size))\n",
        "    return np.arange(middle, size)\n",
        "\n",
        "def get_train_val_test_data_for_users(valid_users):\n",
        "    '''\n",
        "    Splits the data for a list of users into train, val and test, stratified for each session and merginf the session data in the process.\n",
        "    '''\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = [], [], [], [], [], []\n",
        "    for user_id in valid_users:\n",
        "        temp_x_train = np.concatenate([session[get_train_indices(session.shape[0])] for session in users[int(user_id)]['devices'][0]['sessions']])\n",
        "        temp_x_val = np.concatenate([session[get_val_indices(session.shape[0])] for session in users[int(user_id)]['devices'][0]['sessions']])\n",
        "        temp_x_test = np.concatenate([session[get_test_indices(session.shape[0])] for session in users[int(user_id)]['devices'][0]['sessions']])\n",
        "        X_train.append(temp_x_train)\n",
        "        X_val.append(temp_x_val)\n",
        "        X_test.append(temp_x_test)\n",
        "        y_train.append(np.zeros(temp_x_train.shape[0]) + user_id)\n",
        "        y_val.append(np.zeros(temp_x_val.shape[0]) + user_id)\n",
        "        y_test.append(np.zeros(temp_x_test.shape[0]) + user_id)\n",
        "      \n",
        "    X_train = np.concatenate(X_train)\n",
        "    X_val = np.concatenate(X_val)\n",
        "    X_test = np.concatenate(X_test)\n",
        "    y_train = np.concatenate(y_train)\n",
        "    y_val = np.concatenate(y_val)\n",
        "    y_test = np.concatenate(y_test)\n",
        "\n",
        "    encoder = LabelEncoder()\n",
        "    encoder.fit(y_train)\n",
        "    y_train = encoder.transform(y_train)\n",
        "    y_val = encoder.transform(y_val)\n",
        "    y_test = encoder.transform(y_test)\n",
        "\n",
        "    y_train = np_utils.to_categorical(y_train)\n",
        "    y_val = np_utils.to_categorical(y_val)\n",
        "    y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Methods for building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Kkr727D3htTp"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "  '''\n",
        "  Builds the model with the best hyperparameters (128 dense layer)\n",
        "  '''\n",
        "\n",
        "  input_shape = layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))\n",
        "  dropout_rate = 0.1\n",
        "\n",
        "  cnn = layers.Conv2D(64, (3, 3), activation='linear')(input_shape)\n",
        "  cnn = layers.BatchNormalization()(cnn)\n",
        "  cnn = layers.ReLU()(cnn)\n",
        "  cnn = layers.Dropout(dropout_rate)(cnn)\n",
        "\n",
        "  cnn = layers.Conv2D(32, (3, 3), activation='relu')(cnn)\n",
        "  cnn = layers.Dropout(dropout_rate)(cnn)\n",
        "\n",
        "  cnn = layers.Conv2D(32, (3, 3), activation='relu')(cnn)\n",
        "  cnn = layers.Dropout(dropout_rate)(cnn)\n",
        "  cnn = layers.Flatten()(cnn)\n",
        "\n",
        "  dense = layers.Dense(128, activation='relu')(cnn)\n",
        "  dense = layers.Dense(y_train.shape[1])(dense)\n",
        "\n",
        "  output = layers.Softmax()(dense)\n",
        "\n",
        "  model = models.Model(input_shape, output)\n",
        "\n",
        "  lr = 0.001\n",
        "  decay = 0.9\n",
        "  epsilon = 10e-6\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr, beta_1=decay, epsilon=epsilon),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
        "              \n",
        "  return model\n",
        "\n",
        "# Monitor training time\n",
        "class MonitorTime(keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        super(MonitorTime, self).__init__()\n",
        "    \n",
        "    def on_train_begin(self, *args):\n",
        "        self.start_time= time.time()\n",
        "        \n",
        "    def on_train_end(self, *args):\n",
        "        stop_time=time.time()\n",
        "        duration = stop_time- self.start_time             \n",
        "        print(duration) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gVzzUUG0vnh1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [00:20<00:00, 11.13it/s]\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "with open(f'{DATA_PATH}/brainrun_full_not_parsed.pkl', 'rb') as f:\n",
        "    users = pickle.load(f)\n",
        "\n",
        "for user in tqdm(range(len(users))):\n",
        "    parse_user(user)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# User identification experiment\n",
        "Run the experiment to identify the users using the CNN model with the best parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nW-ybrthtTr"
      },
      "outputs": [],
      "source": [
        "valid_users = get_users_over_gestures(140)\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = get_train_val_test_data_for_users(valid_users)\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "# Stop early to avoid overfit\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50, batch_size = 256, validation_data = (X_val, y_val), callbacks=[stop_early, MonitorTime()])\n",
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in3t-7_9lWfA"
      },
      "source": [
        "# Hyperparameter tuning\n",
        "Select the best hyperparameters for a certain model architecture.\n",
        "Only the best model hyperparameter tuning is presented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13btCnhbhtTq"
      },
      "outputs": [],
      "source": [
        "def build_model_with_hp(hp):\n",
        "  '''\n",
        "  Builds the model with the best hyperparameters (128 dense layer)\n",
        "  '''\n",
        "\n",
        "  input_shape = layers.Input(shape=(X_train.shape[1], X_train.shape[2], 1))\n",
        "  dropout_rate = hp.Choice('dropout_rate', [0.0, 0.1, 0.2, 0.3, 0.4])\n",
        "\n",
        "  layer_1_filters = hp.Choice('layer_1_filters', [32, 64, 128])\n",
        "  layer_1_kernel_size = hp.Choice('layer_1_kernel_size', [3, 5])\n",
        "  cnn = layers.Conv2D(layer_1_filters, (layer_1_kernel_size, layer_1_kernel_size), activation='linear')(input_shape)\n",
        "  cnn = layers.BatchNormalization()(cnn)\n",
        "  cnn = layers.ReLU()(cnn)\n",
        "  cnn = layers.Dropout(dropout_rate)(cnn)\n",
        "\n",
        "  layer_2_filters = hp.Choice('layer_2_filters', [32, 64, 128])\n",
        "  cnn = layers.Conv2D(layer_2_filters, (3, 3), activation='relu')(cnn)\n",
        "  cnn = layers.Dropout(dropout_rate)(cnn)\n",
        "\n",
        "  layer_3_filters = hp.Choice('layer_2_filters', [32, 64, 128])\n",
        "  cnn = layers.Conv2D(layer_3_filters, (3, 3), activation='relu')(cnn)\n",
        "  cnn = layers.Dropout(dropout_rate)(cnn)\n",
        "  cnn = layers.Flatten()(cnn)\n",
        "\n",
        "  dense = layers.Dense(128, activation='relu')(cnn)\n",
        "  dense = layers.Dense(y_train.shape[0])(dense)\n",
        "\n",
        "  output = layers.Softmax()(dense)\n",
        "\n",
        "  model = models.Model(input_shape, output)\n",
        "\n",
        "  lr = 0.001\n",
        "  decay = 0.9\n",
        "  epsilon = 10e-6\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr, beta_1=decay, epsilon=epsilon),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
        "              \n",
        "  return model\n",
        "\n",
        "tuner = kt.Hyperband(build_model_with_hp,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=50,\n",
        "                     factor=2,\n",
        "                     directory='model_hypertune',\n",
        "                     project_name='model_1')\n",
        "\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=50, batch_size = 256, validation_data = (X_val, y_val), callbacks=[stop_early])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtzb0b9dq5Ob"
      },
      "source": [
        "# Train models for user authentication\n",
        "\n",
        "Perform 10 iteration, randomly selecting 90% of the users for training and the rest for  testing. Save both the users, models and results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYjVa-yxrH9X"
      },
      "outputs": [],
      "source": [
        "for iteration in range(10):\n",
        "  all_users = get_users_over_gestures(140)\n",
        "  np.random.shuffle(all_users)\n",
        "  train_users = all_users[:int(0.9 * len(all_users))]\n",
        "  test_users = all_users[int(0.9 * len(all_users)):]\n",
        "\n",
        "  X_train, X_val, X_test, y_train, y_val, y_test = get_train_val_test_data_for_users(valid_users)\n",
        "\n",
        "  model = build_model()\n",
        "\n",
        "  # Stop early to avoid overfit\n",
        "  stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "  history = model.fit(X_train, y_train, epochs=50, batch_size = 256, validation_data = (X_val, y_val), callbacks=[stop_early])\n",
        "  test_results = model.evaluate(X_test, y_test)\n",
        "\n",
        "  model.save(f'{MODELS_DIR}/models/simple_cnn_128_embedding_{iteration}.h5')\n",
        "  with open(f'{MODELS_DIR}/results/iteration_{iteration}.pkl', 'wb') as f:\n",
        "      pickle.dump([train_users, test_users, history.history, test_results], f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CNN simple feed gesture points_no_hidden_layer.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "ecc757a38b814f9d9a78e27a3f0556e4d5be26951c473c897a83b93183395c00"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
